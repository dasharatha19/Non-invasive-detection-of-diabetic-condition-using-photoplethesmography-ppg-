{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import warnings \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, classification_report, confusion_matrix, f1_score, recall_score, precision_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from scipy.stats import randint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('filtered_blood_sugar_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1120 entries, 0 to 1119\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   AGE             1120 non-null   int64\n",
      " 1   GENDER          1120 non-null   int64\n",
      " 2   BLOOD PRESSURE  1120 non-null   int64\n",
      " 3   BLOOD SUGAR     1120 non-null   int64\n",
      " 4   PID FUN         1120 non-null   int64\n",
      " 5   CLASS ID        1120 non-null   int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 52.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>BLOOD PRESSURE</th>\n",
       "      <th>BLOOD SUGAR</th>\n",
       "      <th>PID FUN</th>\n",
       "      <th>CLASS ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1120.000000</td>\n",
       "      <td>1120.000000</td>\n",
       "      <td>1120.000000</td>\n",
       "      <td>1120.000000</td>\n",
       "      <td>1120.000000</td>\n",
       "      <td>1120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>55.435714</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>102.819643</td>\n",
       "      <td>198.658929</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.707143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.753477</td>\n",
       "      <td>0.498946</td>\n",
       "      <td>31.730680</td>\n",
       "      <td>93.265118</td>\n",
       "      <td>0.059681</td>\n",
       "      <td>0.455277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1034.000000</td>\n",
       "      <td>1101.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AGE       GENDER  BLOOD PRESSURE  BLOOD SUGAR      PID FUN  \\\n",
       "count  1120.000000  1120.000000     1120.000000  1120.000000  1120.000000   \n",
       "mean     55.435714     0.535714      102.819643   198.658929     0.003571   \n",
       "std      11.753477     0.498946       31.730680    93.265118     0.059681   \n",
       "min      24.000000     0.000000       52.000000    24.000000     0.000000   \n",
       "25%      46.000000     0.000000       92.000000   135.000000     0.000000   \n",
       "50%      55.000000     1.000000      100.000000   179.000000     0.000000   \n",
       "75%      65.000000     1.000000      111.000000   243.000000     0.000000   \n",
       "max      93.000000     1.000000     1034.000000  1101.000000     1.000000   \n",
       "\n",
       "          CLASS ID  \n",
       "count  1120.000000  \n",
       "mean      0.707143  \n",
       "std       0.455277  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('CLASS ID',axis=1)\n",
    "y=df['CLASS ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.2,random_state=0)#splitting data in 80% train, 20%test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8616\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        53\n",
      "           1       0.92      0.90      0.91       171\n",
      "\n",
      "    accuracy                           0.86       224\n",
      "   macro avg       0.81      0.82      0.81       224\n",
      "weighted avg       0.86      0.86      0.86       224\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 39  14]\n",
      " [ 17 154]]\n"
     ]
    }
   ],
   "source": [
    "#Stacking Classifier for AdaBoost and Naive Bayes\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define base models (AdaBoost and Naive Bayes)\n",
    "adaboost = AdaBoostClassifier(n_estimators=100, learning_rate=0.1)\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Define meta-model (Logistic Regression)\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create Stacking Classifier\n",
    "stacked_model = StackingClassifier(estimators=[('adaboost', adaboost), ('naive_bayes', nb_classifier)], final_estimator=meta_model)\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_dist = {\n",
    "    'adaboost__n_estimators': [50, 100],\n",
    "    'adaboost__learning_rate': [0.01, 0.1],\n",
    "    'naive_bayes__var_smoothing': [1e-9, 1e-8],\n",
    "    'final_estimator__C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning with RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(stacked_model, param_dist, cv=5, scoring='accuracy', n_iter=10)\n",
    "\n",
    "# Fit the model with training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best estimator\n",
    "best_stacked_model = random_search.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred = best_stacked_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8616\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        53\n",
      "           1       0.92      0.90      0.91       171\n",
      "\n",
      "    accuracy                           0.86       224\n",
      "   macro avg       0.81      0.82      0.81       224\n",
      "weighted avg       0.86      0.86      0.86       224\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 39  14]\n",
      " [ 17 154]]\n",
      "\n",
      "Best Hyperparameters:\n",
      "{'naive_bayes__var_smoothing': 1e-08, 'final_estimator__C': 0.1, 'adaboost__n_estimators': 50, 'adaboost__learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_excel('filtered_blood_sugar_data.xlsx')\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop('CLASS ID', axis=1)\n",
    "y = df['CLASS ID']\n",
    "\n",
    "# Split data into training and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define base models (AdaBoost and Naive Bayes)\n",
    "adaboost = AdaBoostClassifier(n_estimators=100, learning_rate=0.1)\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Define meta model (Logistic Regression)\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create Stacking Classifier with base models and meta model\n",
    "stacked_model = StackingClassifier(\n",
    "    estimators=[('adaboost', adaboost), ('naive_bayes', nb_classifier)],\n",
    "    final_estimator=meta_model\n",
    ")\n",
    "\n",
    "# Define hyperparameters to tune using RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'adaboost__n_estimators': [50, 100],\n",
    "    'adaboost__learning_rate': [0.01, 0.1],\n",
    "    'naive_bayes__var_smoothing': [1e-9, 1e-8],\n",
    "    'final_estimator__C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV to find best hyperparameters\n",
    "random_search = RandomizedSearchCV(stacked_model, param_dist, cv=5, scoring='accuracy', n_iter=10)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best estimator after RandomizedSearchCV\n",
    "best_stacked_model = random_search.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred = best_stacked_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Display best hyperparameters found during RandomizedSearchCV\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8616\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        53\n",
      "           1       0.92      0.90      0.91       171\n",
      "\n",
      "    accuracy                           0.86       224\n",
      "   macro avg       0.81      0.82      0.81       224\n",
      "weighted avg       0.86      0.86      0.86       224\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 39  14]\n",
      " [ 17 154]]\n",
      "\n",
      "Best Hyperparameters:\n",
      "{'naive_bayes__var_smoothing': 1e-08, 'final_estimator__C': 0.1, 'adaboost__n_estimators': 50, 'adaboost__learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_excel('filtered_blood_sugar_data.xlsx')\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop('CLASS ID', axis=1)\n",
    "y = df['CLASS ID']\n",
    "\n",
    "# Split data into training and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Scale continuous features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Apply scaling to training data\n",
    "X_test = scaler.transform(X_test)  # Apply the same transformation to test data\n",
    "\n",
    "# Define base models\n",
    "adaboost = AdaBoostClassifier(n_estimators=100, learning_rate=0.1)\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Define meta model (Logistic Regression)\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create Stacking Classifier\n",
    "stacked_model = StackingClassifier(\n",
    "    estimators=[('adaboost', adaboost), ('naive_bayes', nb_classifier)],\n",
    "    final_estimator=meta_model\n",
    ")\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_dist = {\n",
    "    'adaboost__n_estimators': [50, 100],  # Number of estimators for AdaBoost\n",
    "    'adaboost__learning_rate': [0.01, 0.1],  # Learning rate for AdaBoost\n",
    "    'naive_bayes__var_smoothing': [1e-9, 1e-8],  # Variance smoothing for Naive Bayes\n",
    "    'final_estimator__C': [0.1, 1, 10]  # Regularization strength for Logistic Regression\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV for hyperparameter tuning\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=stacked_model, \n",
    "    param_distributions=param_dist, \n",
    "    cv=5, \n",
    "    scoring='accuracy', \n",
    "    n_iter=10, \n",
    "    random_state=0\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best model\n",
    "best_stacked_model = random_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_stacked_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Display best hyperparameters\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_excel('filtered_blood_sugar_data.xlsx')\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop('CLASS ID', axis=1)\n",
    "y = df['CLASS ID']\n",
    "\n",
    "# Split data into training and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Scale continuous features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Apply scaling to training data\n",
    "X_test = scaler.transform(X_test)  # Apply the same transformation to test data\n",
    "\n",
    "# Define base models\n",
    "adaboost = AdaBoostClassifier()\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Define meta model (Logistic Regression)\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create Stacking Classifier\n",
    "stacked_model = StackingClassifier(\n",
    "    estimators=[('adaboost', adaboost), ('naive_bayes', nb_classifier)],\n",
    "    final_estimator=meta_model\n",
    ")\n",
    "\n",
    "# Define hyperparameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'adaboost__n_estimators': [50, 100],  # Number of estimators for AdaBoost\n",
    "    'adaboost__learning_rate': [0.01, 0.1],  # Learning rate for AdaBoost\n",
    "    'naive_bayes__var_smoothing': [1e-9, 1e-8],  # Variance smoothing for Naive Bayes\n",
    "    'final_estimator__C': [0.1, 1, 10]  # Regularization strength for Logistic Regression\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=stacked_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=2,  # Optional: Increase verbosity to see progress\n",
    "    n_jobs=-1  # Use all available CPU cores\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best model\n",
    "best_stacked_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_stacked_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Display best hyperparameters\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(grid_search.best_params_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
