{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import warnings \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, classification_report, confusion_matrix, f1_score, recall_score, precision_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from scipy.stats import randint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.read_csv(\"diabetes.csv\")\n",
    "#df = pd.read_excel('Book1.xlsx')\n",
    "df = pd.read_excel('filtered_blood_sugar_data - Copy - Copy.xlsx')\n",
    "#df['GENDER'] = df['GENDER'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1888 entries, 0 to 1887\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   AGE             1888 non-null   int64\n",
      " 1   GENDER          1888 non-null   int64\n",
      " 2   BLOOD PRESSURE  1888 non-null   int64\n",
      " 3   BLOOD SUGAR     1888 non-null   int64\n",
      " 4   PID FUN         1888 non-null   int64\n",
      " 5   CLASS ID        1888 non-null   int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 88.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>BLOOD PRESSURE</th>\n",
       "      <th>BLOOD SUGAR</th>\n",
       "      <th>PID FUN</th>\n",
       "      <th>CLASS ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1888.000000</td>\n",
       "      <td>1888.000000</td>\n",
       "      <td>1888.000000</td>\n",
       "      <td>1888.000000</td>\n",
       "      <td>1888.000000</td>\n",
       "      <td>1888.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.407309</td>\n",
       "      <td>0.317797</td>\n",
       "      <td>90.440148</td>\n",
       "      <td>167.346398</td>\n",
       "      <td>0.148835</td>\n",
       "      <td>0.599047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.033414</td>\n",
       "      <td>0.465743</td>\n",
       "      <td>29.667270</td>\n",
       "      <td>83.458539</td>\n",
       "      <td>0.356020</td>\n",
       "      <td>0.490221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1034.000000</td>\n",
       "      <td>1101.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AGE       GENDER  BLOOD PRESSURE  BLOOD SUGAR      PID FUN  \\\n",
       "count  1888.000000  1888.000000     1888.000000  1888.000000  1888.000000   \n",
       "mean     46.407309     0.317797       90.440148   167.346398     0.148835   \n",
       "std      16.033414     0.465743       29.667270    83.458539     0.356020   \n",
       "min      21.000000     0.000000       24.000000    24.000000     0.000000   \n",
       "25%      32.000000     0.000000       74.000000   114.000000     0.000000   \n",
       "50%      46.000000     0.000000       90.000000   144.000000     0.000000   \n",
       "75%      60.000000     1.000000      104.000000   199.000000     0.000000   \n",
       "max      93.000000     1.000000     1034.000000  1101.000000     1.000000   \n",
       "\n",
       "          CLASS ID  \n",
       "count  1888.000000  \n",
       "mean      0.599047  \n",
       "std       0.490221  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df[df['Pregnancies']==0].shape[0])\n",
    "#print(df[df['Glucose']==0].shape[0])\n",
    "#print(df[df['BloodPressure']==0].shape[0])\n",
    "#print(df[df['SkinThickness']==0].shape[0])\n",
    "#print(df[df['Insulin']==0].shape[0])\n",
    "#print(df[df['BMI']==0].shape[0])\n",
    "#print(df[df['DiabetesPedigreeFunction']==0].shape[0])\n",
    "#print(df[df['Age']==0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>BLOOD PRESSURE</th>\n",
       "      <th>BLOOD SUGAR</th>\n",
       "      <th>PID FUN</th>\n",
       "      <th>CLASS ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1888.000000</td>\n",
       "      <td>1888.000000</td>\n",
       "      <td>1888.000000</td>\n",
       "      <td>1888.000000</td>\n",
       "      <td>1888.000000</td>\n",
       "      <td>1888.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.407309</td>\n",
       "      <td>0.317797</td>\n",
       "      <td>90.440148</td>\n",
       "      <td>167.346398</td>\n",
       "      <td>0.148835</td>\n",
       "      <td>0.599047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.033414</td>\n",
       "      <td>0.465743</td>\n",
       "      <td>29.667270</td>\n",
       "      <td>83.458539</td>\n",
       "      <td>0.356020</td>\n",
       "      <td>0.490221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1034.000000</td>\n",
       "      <td>1101.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AGE       GENDER  BLOOD PRESSURE  BLOOD SUGAR      PID FUN  \\\n",
       "count  1888.000000  1888.000000     1888.000000  1888.000000  1888.000000   \n",
       "mean     46.407309     0.317797       90.440148   167.346398     0.148835   \n",
       "std      16.033414     0.465743       29.667270    83.458539     0.356020   \n",
       "min      21.000000     0.000000       24.000000    24.000000     0.000000   \n",
       "25%      32.000000     0.000000       74.000000   114.000000     0.000000   \n",
       "50%      46.000000     0.000000       90.000000   144.000000     0.000000   \n",
       "75%      60.000000     1.000000      104.000000   199.000000     0.000000   \n",
       "max      93.000000     1.000000     1034.000000  1101.000000     1.000000   \n",
       "\n",
       "          CLASS ID  \n",
       "count  1888.000000  \n",
       "mean      0.599047  \n",
       "std       0.490221  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['Pregnancies']=df['Pregnancies'].replace(0,df['Pregnancies'].mean())\n",
    "#df['Glucose']=df['Glucose'].replace(0,df['Glucose'].mean())\n",
    "#df['BloodPressure']=df['BloodPressure'].replace(0,df['BloodPressure'].mean())\n",
    "#df['SkinThickness']=df['SkinThickness'].replace(0,df['SkinThickness'].mean())\n",
    "#df['Insulin']=df['Insulin'].replace(0,df['Insulin'].mean())\n",
    "#df['BMI']=df['BMI'].replace(0,df['BMI'].mean())\n",
    "\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('CLASS ID',axis=1)\n",
    "y=df['CLASS ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.2,random_state=0)#splitting data in 80% train, 20%test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " KNN Classifier Accuracy: 0.82\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77       148\n",
      "           1       0.86      0.85      0.85       230\n",
      "\n",
      "    accuracy                           0.82       378\n",
      "   macro avg       0.81      0.81      0.81       378\n",
      "weighted avg       0.82      0.82      0.82       378\n",
      "\n",
      "Confusion Matrix:\n",
      "[[115  33]\n",
      " [ 35 195]]\n"
     ]
    }
   ],
   "source": [
    "# KNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "print(f\" KNN Classifier Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_knn)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM Accuracy: 0.88\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       148\n",
      "           1       0.93      0.87      0.90       230\n",
      "\n",
      "    accuracy                           0.88       378\n",
      "   macro avg       0.87      0.88      0.88       378\n",
      "weighted avg       0.88      0.88      0.88       378\n",
      "\n",
      "Confusion Matrix:\n",
      "[[132  16]\n",
      " [ 29 201]]\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier\n",
    "svm = SVC(kernel='linear')  # You can try 'rbf' or 'poly' for different results\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\" SVM Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_svm)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " logistic regression Accuracy: 0.88\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       148\n",
      "           1       0.92      0.88      0.90       230\n",
      "\n",
      "    accuracy                           0.88       378\n",
      "   macro avg       0.87      0.88      0.88       378\n",
      "weighted avg       0.88      0.88      0.88       378\n",
      "\n",
      "Confusion Matrix:\n",
      "[[131  17]\n",
      " [ 28 202]]\n"
     ]
    }
   ],
   "source": [
    "# logistic regression Classifier\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\" logistic regression Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier Accuracy: 0.7434\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.73      0.69       148\n",
      "           1       0.81      0.75      0.78       230\n",
      "\n",
      "    accuracy                           0.74       378\n",
      "   macro avg       0.73      0.74      0.74       378\n",
      "weighted avg       0.75      0.74      0.75       378\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[108  40]\n",
      " [ 57 173]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes classifier\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Train the model\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nb = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred_nb)\n",
    "print(f\"Naive Bayes Classifier Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display additional evaluation metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Naive Bayes Classifier Accuracy (with RandomizedSearchCV): 0.7434\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71       159\n",
      "           1       0.80      0.75      0.77       219\n",
      "\n",
      "    accuracy                           0.74       378\n",
      "   macro avg       0.74      0.74      0.74       378\n",
      "weighted avg       0.75      0.74      0.74       378\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[117  42]\n",
      " [ 55 164]]\n",
      "\n",
      "Best Parameters from RandomizedSearchCV:\n",
      "{'var_smoothing': 0.0003745411188473625}\n"
     ]
    }
   ],
   "source": [
    "#   Naive Bayes (GaussianNB) classifierhyperparameter tuning using RandomizedSearchCV.\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_dist = {\n",
    "    'var_smoothing': uniform(1e-9, 1e-3)  # Smoothing parameter for GaussianNB\n",
    "}\n",
    "\n",
    "# Apply RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=nb_classifier, \n",
    "                                   param_distributions=param_dist, \n",
    "                                   n_iter=100, \n",
    "                                   cv=5, \n",
    "                                   random_state=42, \n",
    "                                   verbose=2, \n",
    "                                   n_jobs=-1)\n",
    "\n",
    "# Fit the RandomizedSearchCV model to find the best parameters\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from the random search\n",
    "best_nb_model = random_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nb = best_nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred_nb)\n",
    "print(f\"Naive Bayes Classifier Accuracy (with RandomizedSearchCV): {accuracy:.4f}\")\n",
    "\n",
    "# Display additional evaluation metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "\n",
    "# Display best parameters found by RandomizedSearchCV\n",
    "print(\"\\nBest Parameters from RandomizedSearchCV:\")\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Gaussian Naive Bayes Classifier Accuracy (with hyperparameter tuning): 0.7434\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71       159\n",
      "           1       0.80      0.75      0.77       219\n",
      "\n",
      "    accuracy                           0.74       378\n",
      "   macro avg       0.74      0.74      0.74       378\n",
      "weighted avg       0.75      0.74      0.74       378\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[117  42]\n",
      " [ 55 164]]\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning for Gaussian Naive Bayes using GridSearchCV\n",
    "# Initialize the Naive Bayes model\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]  # Small smoothing values to add variance\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=nb, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Perform the grid search to find the best hyperparameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model after tuning\n",
    "best_nb = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set using the best model\n",
    "y_pred = best_nb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Gaussian Naive Bayes Classifier Accuracy (with hyperparameter tuning): {accuracy:.4f}\")\n",
    "\n",
    "# Display classification report and confusion matrix\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Accuracy Scores: [0.71854305 0.75827815 0.7384106  0.7218543  0.73178808]\n",
      "Mean Cross-validation Accuracy: 0.7338\n",
      "Standard Deviation of Cross-validation Accuracy: 0.0141\n",
      "Naive Bayes Classifier Accuracy on Test Set: 0.7434\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71       159\n",
      "           1       0.80      0.75      0.77       219\n",
      "\n",
      "    accuracy                           0.74       378\n",
      "   macro avg       0.74      0.74      0.74       378\n",
      "weighted avg       0.75      0.74      0.74       378\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[117  42]\n",
      " [ 55 164]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes classifier with cross validation\n",
    "# Initialize the Naive Bayes classifier with cross validation\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Cross-validation using StratifiedKFold to ensure balanced class distribution\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate using cross-validation on the training data\n",
    "cross_val_scores = cross_val_score(nb_classifier, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation results\n",
    "print(f\"Cross-validation Accuracy Scores: {cross_val_scores}\")\n",
    "print(f\"Mean Cross-validation Accuracy: {np.mean(cross_val_scores):.4f}\")\n",
    "print(f\"Standard Deviation of Cross-validation Accuracy: {np.std(cross_val_scores):.4f}\")\n",
    "\n",
    "# Train the model on the entire training set\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nb = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred_nb)\n",
    "print(f\"Naive Bayes Classifier Accuracy on Test Set: {accuracy:.4f}\")\n",
    "\n",
    "# Display additional evaluation metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best parameters found:  {'C': 1, 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best score found:  0.8172185430463577\n",
      "Accuracy: 0.843915343915344\n",
      "Confusion Matrix:\n",
      " [[140  19]\n",
      " [ 40 179]]\n"
     ]
    }
   ],
   "source": [
    "# svm with hyperparameter tunning\n",
    "# Create the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf', 'poly'],  # Kernel types\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01],  # Kernel coefficient\n",
    "    'degree': [3, 4, 5]  # Degree for 'poly' kernel (only relevant for poly kernel)\n",
    "}\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC()\n",
    "\n",
    "# Initialize the GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best score found: \", grid_search.best_score_)\n",
    "\n",
    "# Get the best estimator\n",
    "best_svm = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred_svm = best_svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model (e.g., accuracy, confusion matrix)\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm)}\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Accuracy: 0.7143\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.69      0.67       159\n",
      "           1       0.76      0.74      0.75       219\n",
      "\n",
      "    accuracy                           0.71       378\n",
      "   macro avg       0.71      0.71      0.71       378\n",
      "weighted avg       0.72      0.71      0.72       378\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[109  50]\n",
      " [ 58 161]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree classifier\n",
    "# Initialize the Decision Tree model\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"Decision Tree Classifier Accuracy: {accuracy_dt:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_dt))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Decision Tree Classifier Accuracy (Tuned): 0.7963\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77       159\n",
      "           1       0.85      0.79      0.82       219\n",
      "\n",
      "    accuracy                           0.80       378\n",
      "   macro avg       0.79      0.80      0.79       378\n",
      "weighted avg       0.80      0.80      0.80       378\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[128  31]\n",
      " [ 46 173]]\n",
      "\n",
      "Best Parameters for Decision Tree:\n",
      "{'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_depth': 40, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree model with hyperparameter tuning\n",
    "# Initialize the Decision Tree model\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_dist_dt = {\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 6],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV for Decision Tree\n",
    "random_search_dt = RandomizedSearchCV(\n",
    "    estimator=dt_classifier,\n",
    "    param_distributions=param_dist_dt,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model with hyperparameter tuning\n",
    "random_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# Get best model and make predictions\n",
    "best_dt_model = random_search_dt.best_estimator_\n",
    "y_pred_dt = best_dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"Decision Tree Classifier Accuracy (Tuned): {accuracy_dt:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_dt))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_dt))\n",
    "\n",
    "# Best parameters\n",
    "print(\"\\nBest Parameters for Decision Tree:\")\n",
    "print(random_search_dt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Accuracy Scores: [0.79801325 0.83774834 0.77483444 0.8013245  0.78476821]\n",
      "Mean Cross-validation Accuracy: 0.7993\n",
      "Standard Deviation of Cross-validation Accuracy: 0.0214\n",
      "Random Forest Classifier Accuracy on Test Set: 0.8148\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79       159\n",
      "           1       0.86      0.82      0.84       219\n",
      "\n",
      "    accuracy                           0.81       378\n",
      "   macro avg       0.81      0.81      0.81       378\n",
      "weighted avg       0.82      0.81      0.82       378\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[129  30]\n",
      " [ 40 179]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest classifier\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Cross-validation using StratifiedKFold to ensure balanced class distribution\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate using cross-validation on the training data\n",
    "cross_val_scores = cross_val_score(rf_classifier, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation results\n",
    "print(f\"Cross-validation Accuracy Scores: {cross_val_scores}\")\n",
    "print(f\"Mean Cross-validation Accuracy: {np.mean(cross_val_scores):.4f}\")\n",
    "print(f\"Standard Deviation of Cross-validation Accuracy: {np.std(cross_val_scores):.4f}\")\n",
    "\n",
    "# Train the model on the entire training set\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Classifier Accuracy on Test Set: {accuracy:.4f}\")\n",
    "\n",
    "# Display additional evaluation metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 648 candidates, totalling 1944 fits\n",
      "Best Hyperparameters: {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Accuracy with Best Hyperparameters: 0.8571\n"
     ]
    }
   ],
   "source": [
    "# random Forest Classifier with hyperparameters tunned using gridsearchcv\n",
    "# Initialize Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define parameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],                # Number of trees\n",
    "    'max_depth': [None, 10, 20, 30],                # Max depth of trees\n",
    "    'min_samples_split': [2, 5, 10],                # Minimum samples to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],                  # Minimum samples at leaf nodes\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],      # Features to consider for splitting\n",
    "    'bootstrap': [True, False]                      # Whether to use bootstrap samples\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, \n",
    "                           cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "# Get the best model\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with Best Hyperparameters: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Best Hyperparameters from RandomizedSearchCV: {'bootstrap': False, 'max_depth': 40, 'max_features': 'sqrt', 'min_samples_leaf': 9, 'min_samples_split': 3, 'n_estimators': 76}\n",
      "Accuracy with Best Hyperparameters from RandomizedSearchCV: 0.8439\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier using randomisedsearchcv\n",
    "# Initialize Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define parameter distribution for tuning\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),           # Number of trees (randomized between 50 and 200)\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],     # Max depth of trees\n",
    "    'min_samples_split': randint(2, 11),         # Min samples to split a node\n",
    "    'min_samples_leaf': randint(1, 11),          # Min samples at leaf nodes\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],    # Features to consider for splitting\n",
    "    'bootstrap': [True, False]                   # Whether to use bootstrap samples\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=rf_classifier, param_distributions=param_dist,\n",
    "                                   n_iter=100, cv=3, verbose=2, random_state=42, \n",
    "                                   n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# Fit RandomizedSearchCV to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the random search\n",
    "best_params_random = random_search.best_params_\n",
    "print(f\"Best Hyperparameters from RandomizedSearchCV: {best_params_random}\")\n",
    "\n",
    "# Get the best model\n",
    "best_rf_model_random = random_search.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred_random = best_rf_model_random.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_random = accuracy_score(y_test, y_pred_random)\n",
    "print(f\"Accuracy with Best Hyperparameters from RandomizedSearchCV: {accuracy_random:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Accuracy: 0.8228\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79       159\n",
      "           1       0.86      0.83      0.84       219\n",
      "\n",
      "    accuracy                           0.82       378\n",
      "   macro avg       0.82      0.82      0.82       378\n",
      "weighted avg       0.82      0.82      0.82       378\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[129  30]\n",
      " [ 37 182]]\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Classifier\n",
    "# Initialize the XGBoost Classifier\n",
    "xgb_classifier = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"XGBoost Classifier Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print detailed evaluation metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy: 0.2908\n",
      "\n",
      "Voting Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      1.00      0.41        49\n",
      "           1       1.00      0.05      0.10       147\n",
      "\n",
      "    accuracy                           0.29       196\n",
      "   macro avg       0.63      0.53      0.26       196\n",
      "weighted avg       0.82      0.29      0.18       196\n",
      "\n",
      "\n",
      "Voting Classifier Confusion Matrix:\n",
      "[[ 49   0]\n",
      " [139   8]]\n"
     ]
    }
   ],
   "source": [
    "# xgboost and naive bayes classifier using voting classifier\n",
    "# Initialize the models\n",
    "nb_classifier = GaussianNB()\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Create a voting classifier combining XGBoost and Naive Bayes\n",
    "voting_clf = VotingClassifier(estimators=[('naive_bayes', nb_classifier), ('xgboost', xgb_classifier)], voting='hard')\n",
    "\n",
    "# Train the combined model\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Voting Classifier Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display classification report and confusion matrix\n",
    "print(\"\\nVoting Classifier Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nVoting Classifier Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Model Accuracy: 0.8673\n",
      "\n",
      "Stacked Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73        49\n",
      "           1       0.91      0.91      0.91       147\n",
      "\n",
      "    accuracy                           0.87       196\n",
      "   macro avg       0.82      0.82      0.82       196\n",
      "weighted avg       0.87      0.87      0.87       196\n",
      "\n",
      "\n",
      "Stacked Model Confusion Matrix:\n",
      "[[ 36  13]\n",
      " [ 13 134]]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Hyperparameter tuning for Naive Bayes (if needed)\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Hyperparameter tuning for XGBoost\n",
    "xgb_params = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "xgb_grid = GridSearchCV(xgb.XGBClassifier(), xgb_params, cv=5, scoring='accuracy')\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "\n",
    "# Create base learners using Naive Bayes and XGBoost\n",
    "base_learners = [\n",
    "    ('naive_bayes', nb_classifier),\n",
    "    ('xgboost', best_xgb)\n",
    "]\n",
    "\n",
    "# Meta-model (Logistic Regression) to combine the predictions from Naive Bayes and XGBoost\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Stacking Classifier that combines the predictions from Naive Bayes and XGBoost using the meta-model\n",
    "stacked_model = StackingClassifier(estimators=base_learners, final_estimator=meta_model)\n",
    "\n",
    "# Train the stacked model\n",
    "stacked_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_stacked = stacked_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred_stacked)\n",
    "print(f\"Stacked Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display classification report and confusion matrix\n",
    "print(\"\\nStacked Model Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_stacked))\n",
    "\n",
    "print(\"\\nStacked Model Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_stacked))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy (without hyperparameter tuning): 0.8163\n",
      "\n",
      "Stacking Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63        49\n",
      "           1       0.88      0.88      0.88       147\n",
      "\n",
      "    accuracy                           0.82       196\n",
      "   macro avg       0.76      0.76      0.76       196\n",
      "weighted avg       0.82      0.82      0.82       196\n",
      "\n",
      "\n",
      "Stacking Classifier Confusion Matrix:\n",
      "[[ 31  18]\n",
      " [ 18 129]]\n"
     ]
    }
   ],
   "source": [
    "# xgboost and naive bayes  (stacking classifier) \n",
    "# Initialize base models for Stacking\n",
    "nb_classifier = GaussianNB()\n",
    "xgb_classifier = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# Initialize final estimator (logistic regression in this case)\n",
    "final_estimator = LogisticRegression()\n",
    "\n",
    "# Create the Stacking Classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[('naive_bayes', nb_classifier), ('xgboost', xgb_classifier)], \n",
    "    final_estimator=final_estimator\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Stacking Classifier Accuracy (without hyperparameter tuning): {accuracy:.4f}\")\n",
    "\n",
    "# Display classification report and confusion matrix\n",
    "print(\"\\nStacking Classifier Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nStacking Classifier Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Stacking Classifier Accuracy (with hyperparameter tuning): 0.8673\n",
      "\n",
      "Stacking Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73        49\n",
      "           1       0.91      0.91      0.91       147\n",
      "\n",
      "    accuracy                           0.87       196\n",
      "   macro avg       0.82      0.82      0.82       196\n",
      "weighted avg       0.87      0.87      0.87       196\n",
      "\n",
      "\n",
      "Stacking Classifier Confusion Matrix:\n",
      "[[ 36  13]\n",
      " [ 13 134]]\n"
     ]
    }
   ],
   "source": [
    "# xgboost and naive bayes  hyperparameter tunned (stacking classifier) \n",
    "# Initialize base models for Stacking\n",
    "nb_classifier = GaussianNB()\n",
    "xgb_classifier = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# Hyperparameter tuning for Naive Bayes\n",
    "nb_param_grid = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "}\n",
    "nb_grid_search = GridSearchCV(nb_classifier, nb_param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "nb_best_model = nb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Hyperparameter tuning for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'n_estimators': [100, 200],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "xgb_grid_search = GridSearchCV(xgb_classifier, xgb_param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "xgb_best_model = xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Initialize final estimator (logistic regression in this case)\n",
    "final_estimator = LogisticRegression()\n",
    "\n",
    "# Create the Stacking Classifier with best models\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[('naive_bayes', nb_best_model.best_estimator_), ('xgboost', xgb_best_model.best_estimator_)],\n",
    "    final_estimator=final_estimator\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Stacking Classifier Accuracy (with hyperparameter tuning): {accuracy:.4f}\")\n",
    "\n",
    "# Display classification report and confusion matrix\n",
    "print(\"\\nStacking Classifier Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nStacking Classifier Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier Accuracy: 0.8724\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75        49\n",
      "           1       0.92      0.91      0.91       147\n",
      "\n",
      "    accuracy                           0.87       196\n",
      "   macro avg       0.83      0.83      0.83       196\n",
      "weighted avg       0.87      0.87      0.87       196\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 37  12]\n",
      " [ 13 134]]\n"
     ]
    }
   ],
   "source": [
    "# Adaboost classifier\n",
    "# intializing the adaboost classifier\n",
    "ada_model = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# Train the AdaBoost model\n",
    "ada_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = ada_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"AdaBoost Classifier Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display additional evaluation metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3010\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.96      0.41        49\n",
      "           1       0.86      0.08      0.15       147\n",
      "\n",
      "    accuracy                           0.30       196\n",
      "   macro avg       0.56      0.52      0.28       196\n",
      "weighted avg       0.71      0.30      0.21       196\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 47   2]\n",
      " [135  12]]\n"
     ]
    }
   ],
   "source": [
    "# Voting Classifier with AdaBoost and Naive Bayes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load dataset and prepare features (X) and target (y)\n",
    "# Assuming X_train, y_train, X_test, y_test are pre-defined\n",
    "\n",
    "# Define AdaBoost and Naive Bayes classifiers\n",
    "adaboost = AdaBoostClassifier(n_estimators=100, learning_rate=0.1)\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Combine AdaBoost and Naive Bayes in a VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=[('adaboost', adaboost), ('naive_bayes', nb_classifier)], voting='soft')\n",
    "\n",
    "# Define hyperparameters to tune using RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'adaboost__n_estimators': [50, 100, 150],\n",
    "    'adaboost__learning_rate': [0.01, 0.1, 0.5],\n",
    "    'naive_bayes__var_smoothing': [1e-9, 1e-8, 1e-7]\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(voting_clf, param_dist, cv=5, scoring='accuracy', n_iter=10)\n",
    "\n",
    "# Fit the model with training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best estimator\n",
    "best_voting_clf = random_search.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred = best_voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8724\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75        49\n",
      "           1       0.92      0.91      0.91       147\n",
      "\n",
      "    accuracy                           0.87       196\n",
      "   macro avg       0.83      0.83      0.83       196\n",
      "weighted avg       0.87      0.87      0.87       196\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 37  12]\n",
      " [ 13 134]]\n"
     ]
    }
   ],
   "source": [
    "#Stacking Classifier for AdaBoost and Naive Bayes\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define base models (AdaBoost and Naive Bayes)\n",
    "adaboost = AdaBoostClassifier(n_estimators=100, learning_rate=0.1)\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Define meta-model (Logistic Regression)\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create Stacking Classifier\n",
    "stacked_model = StackingClassifier(estimators=[('adaboost', adaboost), ('naive_bayes', nb_classifier)], final_estimator=meta_model)\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_dist = {\n",
    "    'adaboost__n_estimators': [50, 100],\n",
    "    'adaboost__learning_rate': [0.01, 0.1],\n",
    "    'naive_bayes__var_smoothing': [1e-9, 1e-8],\n",
    "    'final_estimator__C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning with RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(stacked_model, param_dist, cv=5, scoring='accuracy', n_iter=10)\n",
    "\n",
    "# Fit the model with training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best estimator\n",
    "best_stacked_model = random_search.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred = best_stacked_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 536, number of negative: 246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 297\n",
      "[LightGBM] [Info] Number of data points in the train set: 782, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.685422 -> initscore=0.778803\n",
      "[LightGBM] [Info] Start training from score 0.778803\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Classifier Accuracy: 0.8112\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.63        49\n",
      "           1       0.88      0.86      0.87       147\n",
      "\n",
      "    accuracy                           0.81       196\n",
      "   macro avg       0.75      0.76      0.75       196\n",
      "weighted avg       0.82      0.81      0.81       196\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 32  17]\n",
      " [ 20 127]]\n"
     ]
    }
   ],
   "source": [
    "# LightGBM classifier\n",
    "# Initialize the LightGBM model\n",
    "lgbm = lgb.LGBMClassifier()\n",
    "\n",
    "# Train the model\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lgbm = lgbm.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
    "print(f\"LightGBM Classifier Accuracy: {accuracy_lgbm:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lgbm))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[LightGBM] [Info] Number of positive: 536, number of negative: 246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 297\n",
      "[LightGBM] [Info] Number of data points in the train set: 782, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.685422 -> initscore=0.778803\n",
      "[LightGBM] [Info] Start training from score 0.778803\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Classifier Accuracy (Tuned): 0.8571\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72        49\n",
      "           1       0.91      0.90      0.90       147\n",
      "\n",
      "    accuracy                           0.86       196\n",
      "   macro avg       0.81      0.82      0.81       196\n",
      "weighted avg       0.86      0.86      0.86       196\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 36  13]\n",
      " [ 15 132]]\n",
      "\n",
      "Best Parameters for LightGBM:\n",
      "{'subsample': 0.9, 'num_leaves': 60, 'n_estimators': 400, 'min_child_samples': 40, 'max_depth': 15, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# LightGBM model for hyperparameter tuning\n",
    "# Initialize the LightGBM model\n",
    "lgbm = lgb.LGBMClassifier()\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_dist_lgbm = {\n",
    "    'num_leaves': [20, 30, 40, 50, 60],\n",
    "    'max_depth': [-1, 5, 10, 15, 20],\n",
    "    'learning_rate': [0.1, 0.05, 0.01, 0.001],\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'min_child_samples': [10, 20, 30, 40],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV for LightGBM\n",
    "random_search_lgbm = RandomizedSearchCV(\n",
    "    estimator=lgbm,\n",
    "    param_distributions=param_dist_lgbm,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model with hyperparameter tuning\n",
    "random_search_lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Get best model and make predictions\n",
    "best_lgbm_model = random_search_lgbm.best_estimator_\n",
    "y_pred_lgbm = best_lgbm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
    "print(f\"LightGBM Classifier Accuracy (Tuned): {accuracy_lgbm:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lgbm))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lgbm))\n",
    "\n",
    "# Best parameters\n",
    "print(\"\\nBest Parameters for LightGBM:\")\n",
    "print(random_search_lgbm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier (Random Forest + XGBoost) Accuracy: 0.8622\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72        49\n",
      "           1       0.91      0.91      0.91       147\n",
      "\n",
      "    accuracy                           0.86       196\n",
      "   macro avg       0.82      0.81      0.82       196\n",
      "weighted avg       0.86      0.86      0.86       196\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 35  14]\n",
      " [ 13 134]]\n"
     ]
    }
   ],
   "source": [
    "# adaboost and xgbbost combination\n",
    "# Hyperparameter tuning for Random Forest\n",
    "rf_params = {'n_estimators': [100, 200, 300], 'max_depth': [10, 20, 30], 'min_samples_split': [2, 5, 10]}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(), rf_params, cv=5, scoring='accuracy')\n",
    "rf_grid.fit(X_train, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "\n",
    "# Hyperparameter tuning for XGBoost\n",
    "xgb_params = {'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.3], 'n_estimators': [100, 200]}\n",
    "xgb_grid = GridSearchCV(xgb.XGBClassifier(), xgb_params, cv=5, scoring='accuracy')\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "\n",
    "# Combine Random Forest and XGBoost using VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('rf', best_rf), ('xgb', best_xgb)],\n",
    "    voting='soft'  # Use 'soft' voting, which uses the predicted probabilities for voting\n",
    ")\n",
    "\n",
    "# Train the Voting Classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Voting Classifier (Random Forest + XGBoost) Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display additional evaluation metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Stacking Classifier Accuracy (with hyperparameter tuning for AdaBoost and XGBoost): 0.8724\n",
      "\n",
      "Stacking Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75        49\n",
      "           1       0.92      0.91      0.91       147\n",
      "\n",
      "    accuracy                           0.87       196\n",
      "   macro avg       0.83      0.83      0.83       196\n",
      "weighted avg       0.87      0.87      0.87       196\n",
      "\n",
      "\n",
      "Stacking Classifier Confusion Matrix:\n",
      "[[ 37  12]\n",
      " [ 13 134]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize AdaBoost and XGBoost classifiers\n",
    "ada_boost = AdaBoostClassifier()\n",
    "xgb_classifier = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# Hyperparameter tuning for AdaBoost\n",
    "ada_param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 1.0]\n",
    "}\n",
    "ada_grid_search = GridSearchCV(ada_boost, ada_param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "ada_best_model = ada_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Hyperparameter tuning for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'n_estimators': [100, 200],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "xgb_grid_search = GridSearchCV(xgb_classifier, xgb_param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "xgb_best_model = xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Initialize final estimator (logistic regression in this case)\n",
    "final_estimator = LogisticRegression()\n",
    "\n",
    "# Create the Stacking Classifier with the best models from GridSearchCV\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[('adaboost', ada_best_model.best_estimator_), ('xgboost', xgb_best_model.best_estimator_)],\n",
    "    final_estimator=final_estimator\n",
    ")\n",
    "\n",
    "# Train the Stacking Classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Stacking Classifier Accuracy (with hyperparameter tuning for AdaBoost and XGBoost): {accuracy:.4f}\")\n",
    "\n",
    "# Display classification report and confusion matrix\n",
    "print(\"\\nStacking Classifier Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nStacking Classifier Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AdaBoost Classifier Accuracy: 0.8724\n",
      "Best Hyperparameters: {'algorithm': 'SAMME.R', 'learning_rate': 0.01, 'n_estimators': 150}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75        49\n",
      "           1       0.92      0.91      0.91       147\n",
      "\n",
      "    accuracy                           0.87       196\n",
      "   macro avg       0.83      0.83      0.83       196\n",
      "weighted avg       0.87      0.87      0.87       196\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 37  12]\n",
      " [ 13 134]]\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost classifier with hyperparameter tunning\n",
    "# Initialize the AdaBoost classifier\n",
    "ada_model = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],          # Number of weak learners\n",
    "    'learning_rate': [0.01, 0.1, 1.0],       # Learning rate for AdaBoost\n",
    "    'algorithm': ['SAMME', 'SAMME.R']        # Different boosting algorithms\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the AdaBoost model and parameter grid\n",
    "grid_search = GridSearchCV(estimator=ada_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV to find the best hyperparameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model after hyperparameter tuning\n",
    "best_ada_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set with the best model\n",
    "y_pred = best_ada_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Best AdaBoost Classifier Accuracy: {accuracy:.4f}\")\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Display additional evaluation metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy: 0.8520\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        49\n",
      "           1       0.92      0.88      0.90       147\n",
      "\n",
      "    accuracy                           0.85       196\n",
      "   macro avg       0.80      0.82      0.81       196\n",
      "weighted avg       0.86      0.85      0.85       196\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 37  12]\n",
      " [ 17 130]]\n"
     ]
    }
   ],
   "source": [
    "# combining both logistic regression and svm \n",
    "# Initialize the base models\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "svm = SVC(probability=True, random_state=42)  # Set probability=True for VotingClassifier compatibility\n",
    "\n",
    "# Create a Voting Classifier with Logistic Regression and SVM\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('Logistic Regression', log_reg), ('SVM', svm)],\n",
    "    voting='soft'  # 'soft' voting uses predicted probabilities, 'hard' uses majority voting\n",
    ")\n",
    "\n",
    "# Train the ensemble model\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Voting Classifier Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print detailed evaluation metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy: 0.8520\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        49\n",
      "           1       0.92      0.88      0.90       147\n",
      "\n",
      "    accuracy                           0.85       196\n",
      "   macro avg       0.80      0.82      0.81       196\n",
      "weighted avg       0.86      0.85      0.85       196\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 37  12]\n",
      " [ 17 130]]\n"
     ]
    }
   ],
   "source": [
    "# combining teh svm,logistic regression and knn \n",
    "# Initialize the base classifiers\n",
    "svm_clf = SVC(kernel='linear', probability=True)  # Set probability=True for soft voting\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "log_reg_clf = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Combine the models using VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('svm', svm_clf), ('knn', knn_clf), ('log_reg', log_reg_clf)],\n",
    "    voting='soft'  # 'hard' for majority voting, 'soft' for weighted average of probabilities\n",
    ")\n",
    "\n",
    "# Train the Voting Classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Voting Classifier Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display additional evaluation metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy with Hyperparameter Tuning: 0.8571\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72        49\n",
      "           1       0.91      0.90      0.90       147\n",
      "\n",
      "    accuracy                           0.86       196\n",
      "   macro avg       0.81      0.82      0.81       196\n",
      "weighted avg       0.86      0.86      0.86       196\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 36  13]\n",
      " [ 15 132]]\n"
     ]
    }
   ],
   "source": [
    "# combining the svm,logistic regression and knn with Hyperparameter tuning \n",
    "# Hyperparameter tuning for SVM\n",
    "svm_params = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "svm_grid = GridSearchCV(SVC(probability=True), svm_params, cv=5, scoring='accuracy')\n",
    "svm_grid.fit(X_train, y_train)\n",
    "best_svm = svm_grid.best_estimator_\n",
    "\n",
    "# Hyperparameter tuning for KNN\n",
    "knn_params = {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance']}\n",
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5, scoring='accuracy')\n",
    "knn_grid.fit(X_train, y_train)\n",
    "best_knn = knn_grid.best_estimator_\n",
    "\n",
    "# Hyperparameter tuning for Logistic Regression\n",
    "log_reg_params = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}\n",
    "log_reg_grid = GridSearchCV(LogisticRegression(max_iter=500), log_reg_params, cv=5, scoring='accuracy')\n",
    "log_reg_grid.fit(X_train, y_train)\n",
    "best_log_reg = log_reg_grid.best_estimator_\n",
    "\n",
    "# Combine the tuned models using VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('svm', best_svm), ('knn', best_knn), ('log_reg', best_log_reg)],\n",
    "    voting='soft'  # 'soft' uses predicted probabilities for voting\n",
    ")\n",
    "\n",
    "# Train the Voting Classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Voting Classifier Accuracy with Hyperparameter Tuning: {accuracy:.4f}\")\n",
    "\n",
    "# Display additional evaluation metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Ensemble Accuracy: 0.8418\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.69        49\n",
      "           1       0.90      0.89      0.89       147\n",
      "\n",
      "    accuracy                           0.84       196\n",
      "   macro avg       0.79      0.79      0.79       196\n",
      "weighted avg       0.84      0.84      0.84       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stacking ensemble combines KNN, SVM, Logistic Regression, Random Forest, and XGBoost with a meta-learner:\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "    ('svm', SVC(probability=True, kernel='linear')),\n",
    "    ('log_reg', LogisticRegression()),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n",
    "]\n",
    "\n",
    "# Define the meta-learner\n",
    "meta_learner = LogisticRegression()\n",
    "\n",
    "# Create the stacking ensemble\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_learner, cv=5)\n",
    "\n",
    "# Train the stacking model\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Stacking Ensemble Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Detailed metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Stacking Ensemble Accuracy: 0.8724\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75        49\n",
      "           1       0.92      0.91      0.91       147\n",
      "\n",
      "    accuracy                           0.87       196\n",
      "   macro avg       0.83      0.83      0.83       196\n",
      "weighted avg       0.87      0.87      0.87       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stacking ensemble combines KNN, SVM, Logistic Regression, Random Forest, and XGBoost with a meta-learner with hyperparameter tunning\n",
    "# Define hyperparameters for each model\n",
    "knn_params = {'n_neighbors': [3, 5, 7]}\n",
    "svm_params = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "rf_params = {'n_estimators': [100, 200], 'max_depth': [5, 10, None]}\n",
    "xgb_params = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]}\n",
    "logreg_params = {'C': [0.01, 0.1, 1, 10], 'solver': ['liblinear']}\n",
    "\n",
    "# Tune each base model using GridSearchCV\n",
    "knn = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5).fit(X_train, y_train).best_estimator_\n",
    "svm = GridSearchCV(SVC(probability=True), svm_params, cv=5).fit(X_train, y_train).best_estimator_\n",
    "rf = GridSearchCV(RandomForestClassifier(), rf_params, cv=5).fit(X_train, y_train).best_estimator_\n",
    "xgb = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss'), xgb_params, cv=5).fit(X_train, y_train).best_estimator_\n",
    "logreg = GridSearchCV(LogisticRegression(), logreg_params, cv=5).fit(X_train, y_train).best_estimator_\n",
    "\n",
    "# Define the meta-learner and tune it as well\n",
    "meta_learner_params = {'C': [0.1, 1, 10]}\n",
    "meta_learner = GridSearchCV(LogisticRegression(), meta_learner_params, cv=5).fit(X_train, y_train).best_estimator_\n",
    "\n",
    "# Create the stacking ensemble with tuned models, including Logistic Regression as a base model\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[('knn', knn), ('svm', svm), ('rf', rf), ('xgb', xgb), ('logreg', logreg)],\n",
    "    final_estimator=meta_learner,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Train the stacking model\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Tuned Stacking Ensemble Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Detailed metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC curve \n",
    "\n",
    "def plot_roc_curve(y_true, X_test, model, model_name):\n",
    "    # Check if model has predict_proba or decision_function for ROC\n",
    "    if hasattr(model, \"predict_proba\"):  # Use `predict_proba` if available\n",
    "        y_score = model.predict_proba(X_test)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):  # Use `decision_function` for models like SVM\n",
    "        y_score = model.decision_function(X_test)\n",
    "    else:\n",
    "        print(f\"{model_name} does not support ROC plot as it lacks probability predictions.\")\n",
    "        return\n",
    "    \n",
    "    # Compute ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})', lw=2)\n",
    "\n",
    "# Initialize the plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot ROC for each model using y_test as ground truth\n",
    "plot_roc_curve(y_test, X_test, knn, \"KNN\")\n",
    "plot_roc_curve(y_test, X_test, svm, \"SVM\")\n",
    "plot_roc_curve(y_test, X_test, model, \"Logistic Regression\")\n",
    "\n",
    "# Add plot labels and legend\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)  # Diagonal line for random classifier\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for KNN, SVM, and Logistic Regression')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
